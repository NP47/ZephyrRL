{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.training_algorithms.reinforce import REINFORCE\n",
    "from src.env.sailboat_env import SailboatEnv\n",
    "\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Reward -1.299171729381399\n",
      "Episode: 10 Reward -1.196550663448508\n",
      "Episode: 20 Reward -1.6455684095587726\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39msample_action(obs)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Step return type - `tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]`\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# These represent the next observation, the reward from the step,\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# if the episode is terminated, if the episode is truncated and\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# additional info from the step\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#this needs to be changed\u001b[39;00m\n\u001b[1;32m     32\u001b[0m agent\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[1;32m     33\u001b[0m episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/MSc Mathematics RUG/Study/2024-2025/1b/Deep Learning/ZephyrRL/src/env/sailboat_env.py:320\u001b[0m, in \u001b[0;36mSailboatEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    317\u001b[0m delta_theta_boat \u001b[38;5;241m=\u001b[39m action\n\u001b[1;32m    318\u001b[0m prev_dist \u001b[38;5;241m=\u001b[39m distance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msailboat\u001b[38;5;241m.\u001b[39mpos(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msailboat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta_theta_boat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta_wind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta_wind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m dist \u001b[38;5;241m=\u001b[39m distance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msailboat\u001b[38;5;241m.\u001b[39mpos(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m    324\u001b[0m r \u001b[38;5;241m=\u001b[39m (prev_dist \u001b[38;5;241m-\u001b[39m dist)\u001b[38;5;241m/\u001b[39mscale_factor \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n",
      "File \u001b[0;32m~/MSc Mathematics RUG/Study/2024-2025/1b/Deep Learning/ZephyrRL/src/env/sailboat_env.py:169\u001b[0m, in \u001b[0;36mSailboat.step\u001b[0;34m(self, delta_theta_b, wind_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta_boat,) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    166\u001b[0m z \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_y]\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_y \u001b[38;5;241m=\u001b[39m \u001b[43mrkf45_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_ode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_y\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/MSc Mathematics RUG/Study/2024-2025/1b/Deep Learning/ZephyrRL/src/env/sailboat_env.py:22\u001b[0m, in \u001b[0;36mrkf45_step\u001b[0;34m(f, t, z, h, args)\u001b[0m\n\u001b[1;32m     20\u001b[0m k4 \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m*\u001b[39m f(t \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m*\u001b[39m h, z \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1932\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2197\u001b[39m) \u001b[38;5;241m*\u001b[39m k1 \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m7200\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2197\u001b[39m) \u001b[38;5;241m*\u001b[39m k2 \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m7296\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2197\u001b[39m) \u001b[38;5;241m*\u001b[39m k3, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     21\u001b[0m k5 \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m*\u001b[39m f(t \u001b[38;5;241m+\u001b[39m h, z \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m439\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m216\u001b[39m) \u001b[38;5;241m*\u001b[39m k1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m k2 \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m3680\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m513\u001b[39m) \u001b[38;5;241m*\u001b[39m k3 \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m845\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4104\u001b[39m) \u001b[38;5;241m*\u001b[39m k4, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 22\u001b[0m k6 \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m*\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m27\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3544\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2565\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1859\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m4104\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk4\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m z_next \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m16\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m135\u001b[39m) \u001b[38;5;241m*\u001b[39m k1 \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m6656\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m12825\u001b[39m) \u001b[38;5;241m*\u001b[39m k3 \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m28561\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m56430\u001b[39m) \u001b[38;5;241m*\u001b[39m k4 \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m9\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m*\u001b[39m k5 \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m55\u001b[39m) \u001b[38;5;241m*\u001b[39m k6\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_next\n",
      "File \u001b[0;32m~/MSc Mathematics RUG/Study/2024-2025/1b/Deep Learning/ZephyrRL/src/env/sailboat_env.py:93\u001b[0m, in \u001b[0;36msystem_ode\u001b[0;34m(t, z, theta_b, theta_s, theta_w, mag_w_v_t, fixed_param)\u001b[0m\n\u001b[1;32m     90\u001b[0m v_b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([v_x, v_y])\n\u001b[1;32m     91\u001b[0m v_a \u001b[38;5;241m=\u001b[39m v_t \u001b[38;5;241m-\u001b[39m v_b\n\u001b[0;32m---> 93\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[43mangle_of_atack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m C_L, C_D \u001b[38;5;241m=\u001b[39m lift_coefficient(), drag_coefficient()\n\u001b[1;32m     97\u001b[0m L \u001b[38;5;241m=\u001b[39m lift(C_L, rho, S, v_a, alpha)\n",
      "File \u001b[0;32m~/MSc Mathematics RUG/Study/2024-2025/1b/Deep Learning/ZephyrRL/src/env/sailboat_env.py:71\u001b[0m, in \u001b[0;36mangle_of_atack\u001b[0;34m(v_b, v_a)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mangle_of_atack\u001b[39m(v_b, v_a):\n\u001b[0;32m---> 71\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marccos(\u001b[38;5;241m-\u001b[39m(np\u001b[38;5;241m.\u001b[39mdot(v_a,v_b))\u001b[38;5;241m/\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(v_a)\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_b\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m alpha\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py:2553\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2552\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdot(x)\n\u001b[0;32m-> 2553\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   2555\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mreshape(ndim\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create and wrap the environment\n",
    "env = SailboatEnv()\n",
    "\n",
    "\n",
    "total_num_episodes = int(5e3)  # Total number of episodes\n",
    "\n",
    "\n",
    "obs_space_dims = 8 #create obervation space\n",
    "action_space_dims = 1 #create action space\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "# Reinitialize agent every seed\n",
    "agent = REINFORCE(obs_space_dims, action_space_dims)\n",
    "reward_over_episodes = []\n",
    "\n",
    "for episode in range(total_num_episodes):\n",
    "    \n",
    "    obs = env.reset() \n",
    "\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.sample_action(obs)\n",
    "\n",
    "        # Step return type - `tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]`\n",
    "        # These represent the next observation, the reward from the step,\n",
    "        # if the episode is terminated, if the episode is truncated and\n",
    "        # additional info from the step\n",
    "        obs, reward, done, info = env.step(action) #this needs to be changed\n",
    "        agent.rewards.append(reward)\n",
    "        episode_reward += reward\n",
    "        # End the episode when either truncated or terminated is true\n",
    "        #  - truncated: The episode duration reaches max number of timesteps\n",
    "        #  - terminated: Any of the state space values is no longer finite.\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            \n",
    "        \n",
    "            time.sleep(1/60)\n",
    "            env.draw()\n",
    "\n",
    "\n",
    "    reward_over_episodes.append(episode_reward) \n",
    "    agent.update()\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "        avg_reward = np.mean(reward_over_episodes)\n",
    "        print('Episode:', episode, 'Reward', episode_reward)\n",
    "    \n",
    "        time.sleep(1/60)\n",
    "        env.draw()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
